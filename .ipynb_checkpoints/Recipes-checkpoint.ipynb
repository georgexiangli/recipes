{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Cuisines Using Ingredient List\n",
    "\n",
    "Use recipe data from the What Cooking? data set [https://www.kaggle.com/c/whats-cooking/overview] from Yummly and Kaggle to predict the cuisine of a recipe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "There exist staple ingredients that can predict the cuisine of a recipe.\n",
    "\n",
    "Examples: Rice, butter, soy souce, flour, feta cheese.\n",
    "\n",
    "We don't want to overfit our model by predicting on rare ingredients, so we might want look into the most ingredients in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'id': 10259, 'cuisine': 'greek', 'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open('train.json')\n",
    "data = json.load(f)\n",
    "\n",
    "# TODO: Preprocess test data separately\n",
    "f = open('test.json')\n",
    "# data = data + (json.load(f))\n",
    "\n",
    "print(type(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>29109</td>\n",
       "      <td>irish</td>\n",
       "      <td>[light brown sugar, granulated sugar, butter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>11462</td>\n",
       "      <td>italian</td>\n",
       "      <td>[KRAFT Zesty Italian Dressing, purple onion, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>2238</td>\n",
       "      <td>irish</td>\n",
       "      <td>[eggs, citrus fruit, raisins, sourdough starte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39772</th>\n",
       "      <td>41882</td>\n",
       "      <td>chinese</td>\n",
       "      <td>[boneless chicken skinless thigh, minced garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39773</th>\n",
       "      <td>2362</td>\n",
       "      <td>mexican</td>\n",
       "      <td>[green chile, jalapeno chilies, onions, ground...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39774 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      cuisine                                        ingredients\n",
       "0      10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "1      25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2      20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3      22213       indian                [water, vegetable oil, wheat, salt]\n",
       "4      13162       indian  [black pepper, shallots, cornflour, cayenne pe...\n",
       "...      ...          ...                                                ...\n",
       "39769  29109        irish  [light brown sugar, granulated sugar, butter, ...\n",
       "39770  11462      italian  [KRAFT Zesty Italian Dressing, purple onion, b...\n",
       "39771   2238        irish  [eggs, citrus fruit, raisins, sourdough starte...\n",
       "39772  41882      chinese  [boneless chicken skinless thigh, minced garli...\n",
       "39773   2362      mexican  [green chile, jalapeno chilies, onions, ground...\n",
       "\n",
       "[39774 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique classes and check for imbalance\n",
    "value_counts = df['cuisine'].value_counts()\n",
    "\n",
    "print(\"Total classes: %d\" % (len(value_counts)))\n",
    "\n",
    "num_examples = len(df.index)\n",
    "print(\"Total examples: %d\" % (num_examples))\n",
    "\n",
    "# Store labels and counts for bar graph\n",
    "labels = []\n",
    "counts = []\n",
    "\n",
    "for label, content in value_counts.items():\n",
    "    print(\"%-*s%d\\t%1.4f\" % (16, label, content, (content / num_examples)))\n",
    "    labels.append(label)\n",
    "    counts.append(content)\n",
    "    \n",
    "# 14 out of the 20 features contain less than 5% of the features each\n",
    "# We'll need to account for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot recipe counts per cuisine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (30, 8))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "plt.bar(labels, counts, width = .6)\n",
    "\n",
    "ax.set_title('Recipe Counts', fontsize = 48) \n",
    "ax.set_xlabel('Cuisines', fontsize = 32)\n",
    "ax.set_ylabel('Counts', fontsize = 32)\n",
    "ax.tick_params(axis=\"x\", labelsize=18)\n",
    "ax.tick_params(axis=\"y\", labelsize=24)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural language processing techniques\n",
    "# Porter Stemmer not too useful for breaking down ingredients to root\n",
    "# Can't reduce Kraft cheese to cheese\n",
    "\n",
    "from nltk import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "words = [\"cheese\", \"cheeses\", \"cheesy\", \"Kraft Cheese\", \"boneless\", \"bone-in\", \"cream\", \"low-fat cream\"] \n",
    "  \n",
    "for w in words: \n",
    "    print(w, \" : \", ps.stem(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words\n",
    "\n",
    "# For recipes, remove measurements\n",
    "stop_words = {\"gram\", \" g\", \"kilogram\", \"kg\", \"milliliter\", \"ml\", \n",
    "                 \"ounce\", \"oz\", \"pound\", \"lb\", \"cup\", \"tablespoon\", \"tbsp\", \"teaspoon\", \"tsp\",\n",
    "                 \"inch\", \"-\", \"%\", \"&\"\n",
    "                 }\n",
    "\n",
    "# Remove numerical values\n",
    "for num in range(1001):\n",
    "    stop_words.add(str(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ingredient list\n",
    "ingredients_corpus = []\n",
    "translated_ingredients_list = []\n",
    "for recipe in data:\n",
    "    # Remove spaces in list entries to preserve difference between 'grape tomatoes' and 'grape' and 'tomatoes'\n",
    "    ingredients_list = [item.lower().replace(' ','') for item in recipe['ingredients'] if not any(stop_word in item for stop_word in stop_words)]\n",
    "    translated_ingredients_list.append(ingredients_list)\n",
    "    ingredients_str = ' '.join(ingredients_list)\n",
    "    ingredients_corpus.append(ingredients_str)\n",
    "    \n",
    "df['translated_ingredients'] = translated_ingredients_list\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common ingredients per cuisine\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counter = {}\n",
    "\n",
    "for cuisine in df['cuisine'].unique():\n",
    "    counter[cuisine] = Counter()\n",
    "    # Find rows belonging to the cuisine\n",
    "    indices = (df['cuisine'] == cuisine)\n",
    "    \n",
    "    # For each row belonging to the cuisine, update counter with list of translated ingredients\n",
    "    for ingredients in df[indices]['translated_ingredients']:\n",
    "        counter[cuisine].update(ingredients)\n",
    "\n",
    "topData = []\n",
    "topSet = set()\n",
    "\n",
    "for cuisine in counter.keys():\n",
    "    cuisineTop = {\n",
    "        'cuisine':cuisine\n",
    "    }\n",
    "    \n",
    "    for i in range(0, 50):\n",
    "        headerVal = \"Top \" + str(i + 1)\n",
    "        topIngredient = counter[cuisine].most_common(50)[i][0]\n",
    "        cuisineTop[headerVal] = topIngredient\n",
    "        topSet.add(topIngredient)\n",
    "        \n",
    "    topData.append(cuisineTop)\n",
    "\n",
    "topDf = pd.DataFrame(topData) \n",
    "topDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words in each recipe\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(dtype = 'uint8')\n",
    "\n",
    "X = vectorizer.fit_transform(ingredients_corpus)\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "print(len(features))\n",
    "print(features[0:50])\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# Conversion to sparse matrix\n",
    "vectorizer_data = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get total counts for each ingredient across recipes\n",
    "feature_counts = vectorizer_data.sum(axis = 0)\n",
    "print(\"Feature count: %d\" % (len(feature_counts)))\n",
    "\n",
    "# Percentile of ingredients that appear in 50 or more recipes\n",
    "percentile = round(sum(feature_counts < 50) / len(feature_counts), 4)\n",
    "print(\"Percentile: %1.4f\" % (percentile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab mask of where ingredient is used 50 times or more in data set\n",
    "# Choose 50 because in the best case the ingredient shows up in ~10% of a cuisine's recipes\n",
    "states = feature_counts > 50\n",
    "\n",
    "remaining_indices = list(np.where(states == True)[0])\n",
    "deleted_indices = list(np.where(states == False)[0])\n",
    "\n",
    "features = np.array(features)\n",
    "features_min50 = features[remaining_indices]\n",
    "\n",
    "vectorizer_data_min50 = np.delete(vectorizer_data, deleted_indices, axis = 1)\n",
    "\n",
    "print(vectorizer_data_min50.shape)\n",
    "print(vectorizer_data.shape)\n",
    "\n",
    "vectorized_df_min50 = pd.DataFrame(data = vectorizer_data_min50, columns = features_min50)\n",
    "vectorized_df = pd.DataFrame(data = vectorizer_data, columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(vectorized_df_min50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['id']\n",
    "del df['ingredients']\n",
    "del df['translated_ingredients']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cuisine']\n",
    "del df['cuisine']\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Implementation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "log_fit = log_clf.fit(X_train, y_train)\n",
    "log_pred = log_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model performs well on Mexican and Indian food\n",
    "# Performance is poor on cuisine with fewer examples\n",
    "# Performance on Italian and southern US food can be improved though they are among the most represented in the data set\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, log_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar trend to logistic regression\n",
    "# Worse overall\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_fit = dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print(classification_report(y_test, dt_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Similar trends and performance to logistic regression\n",
    "# Reduced n_estimators because precision was high but recall was low, implying overfit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators = 50)\n",
    "rf_fit = rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, rf_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding support vector machine for high dimensional problem\n",
    "# LinearSVC due to large data set\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "svc_clf = LinearSVC()\n",
    "svc_fit = svc_clf.fit(X_train, y_train)\n",
    "svc_pred = svc_clf.predict(X_test)\n",
    "print(classification_report(y_test, svc_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential Overfit\n",
    "# Model could be looking at a highly specific set of ingredients\n",
    "# Solutions: Reduce feature count, find alternative methods of feature engineering\n",
    "# Next step: TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(ingredients_corpus)\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "# Conversion to sparse matrix\n",
    "vectorizer_data = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "X = pd.DataFrame(data = vectorizer_data, columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "log_clf = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "log_fit = log_clf.fit(X_train, y_train)\n",
    "log_pred = log_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall, slightly better scores than count vectorization\n",
    "# Precision is decent but recall is bad, potential overfit?\n",
    "# We can try dropping features with low TFIDF, this can help drop ingredients that are common across all cuisines\n",
    "\n",
    "print(classification_report(y_test, log_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 1000 TFIDF features\n",
    "vectorizer = TfidfVectorizer(max_features = 1000)\n",
    "X = vectorizer.fit_transform(ingredients_corpus)\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "# Conversion to sparse matrix\n",
    "vectorizer_data = X.toarray()\n",
    "\n",
    "features = np.array(features)\n",
    "X = pd.DataFrame(data = vectorizer_data, columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "log_fit = log_clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "log_pred = log_fit.predict(X_test_tfidf)\n",
    "\n",
    "# Slightly lower scores, we might be throwing away useful data\n",
    "print(classification_report(y_test_tfidf, log_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding support vector machine for high dimensional problem\n",
    "# LinearSVC due to large data set\n",
    "\n",
    "svc_clf = LinearSVC()\n",
    "svc_fit = svc_clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "svc_pred = svc_clf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test_tfidf, svc_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on 50 most common features per cuisine\n",
    "topList = list(topSet)\n",
    "\n",
    "print(vectorized_df.shape)\n",
    "vectorized_df = vectorized_df[topList]\n",
    "\n",
    "print(vectorized_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_df, y, test_size=0.25, random_state=27)\n",
    "\n",
    "log_clf = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "log_fit = log_clf.fit(X_train, y_train)\n",
    "log_pred = log_fit.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, log_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding support vector machine for high dimensional problem\n",
    "# LinearSVC due to large data set\n",
    "\n",
    "svc_clf = LinearSVC()\n",
    "svc_fit = svc_clf.fit(X_train, y_train)\n",
    "svc_pred = svc_clf.predict(X_test)\n",
    "print(classification_report(y_test, svc_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance is decent for some cuisines, but poor for others\n",
    "# Implement XGBoost to better classify cuisines that the model is struggling with\n",
    "# Compare between TF IDF and most common features\n",
    "\n",
    "# XGBoost with most common features\n",
    "# Similar performance to non-boosted models\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimators = 100, max_depth = 3)\n",
    "xgb_model.fit(X_train, y_train, eval_metric = 'mlogloss')\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, xgb_pred, zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost on TFIDF\n",
    "# Call fit again, overwrite model weights, just like sklearn API [https://xgboost.readthedocs.io/en/latest/python/python_api.html]\n",
    "# Similar performance\n",
    "\n",
    "xgb_model.fit(X_train_tfidf, y_train_tfidf, eval_metric = 'mlogloss')\n",
    "xgb_pred = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "print(classification_report(y_test_tfidf, xgb_pred, zero_division = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
